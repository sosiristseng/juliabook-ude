{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2385e8-96d9-4683-ade2-3cf50cb3ac6a",
   "metadata": {},
   "source": [
    "# Training a Neural ODE\n",
    "\n",
    "From [this blog post](https://julialang.org/blog/2019/01/fluxdiffeq/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5c4e9",
   "metadata": {},
   "source": [
    "## Generating a toy dataset\n",
    "\n",
    "The data were sampled in the [Lotka-Volterra equations](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations) describing the dynamics of the population of rabbits and wolves. The [Neural ODEs](https://arxiv.org/abs/1806.07366) will be trained on those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e0bd6-cfe1-42fc-8361-2fb977d8d0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T13:51:51.177000Z",
     "iopub.status.busy": "2022-02-22T13:51:50.611000Z",
     "iopub.status.idle": "2022-02-22T13:52:06.112000Z",
     "shell.execute_reply": "2022-02-22T13:52:06.078000Z"
    }
   },
   "outputs": [],
   "source": [
    "using DifferentialEquations\n",
    "\n",
    "function lotka_volterra!(du,u,p,t)\n",
    "  x, y = u\n",
    "  α, β, δ, γ = p\n",
    "  du[1] = dx = α*x - β*x*y\n",
    "  du[2] = dy = -δ*y + γ*x*y\n",
    "end\n",
    "\n",
    "u0 = [1.0, 1.0]\n",
    "tspan = (0.0, 10.0)\n",
    "p = [1.5, 1.0, 3.0, 1.0]\n",
    "prob = ODEProblem(lotka_volterra!,u0,tspan,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48adbf",
   "metadata": {},
   "source": [
    "The solution looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ddde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve(prob)\n",
    "using Plots\n",
    "plot(sol)\n",
    "scatter!(t->sol(t)[1], 0:0.1:10.0, label=\"Data Points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e4f15",
   "metadata": {},
   "source": [
    "Define a neural network with the function as the single layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, DiffEqFlux\n",
    "\n",
    "# Initial Parameter Vector\n",
    "p = [2.2, 1.0, 2.0, 0.4]\n",
    "# Put the Parameter Vector into Flux.jl\n",
    "params = Flux.params(p)\n",
    "\n",
    "# The 1-layer \"neural network\"\n",
    "function predict_rd() \n",
    "    solve(prob,Tsit5(),p=p,saveat=0.1)[1,:] # override with new parameters\n",
    "end\n",
    "\n",
    "# loss function\n",
    "loss_rd() = sum(abs2, x-1 for x in predict_rd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c420ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Iterators.repeated((), 100)\n",
    "opt = ADAM(0.1)\n",
    "\n",
    "# callback function to observe training\n",
    "cb = function () \n",
    "  display(loss_rd())\n",
    "  # using `remake` to re-create our `prob` with current parameters `p`\n",
    "  display(plot(solve(remake(prob,p=p),Tsit5(),saveat=0.1),ylim=(0,7)))\n",
    "end\n",
    "\n",
    "# Display the ODE with the initial parameter values.\n",
    "cb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss_rd, params, data, opt, cb = cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
